{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Analise de sentimento"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "baseado no post do medium de: https://medium.com/@alegeorgelustosa/an%C3%A1lise-de-sentimentos-em-python-2a7d04a836e0"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Para esse exemplo foi uitlizado uma base de textos, já classificados, obtidos a partir do post original do medium. A partir dessa base vamos treinar um modelo bayesiano que será capaz de predizer o sentimento com as possíveis labels: Alegria, Nojo, Medo, Raíva, Surpresa e Tristeza."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Imports\n",
    "\n",
    "Vamos carregar as bibliotecas necessárias para executar o exemplo."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "source": [
    "##  Read csv file\n",
    "\n",
    "Vamos carregar o dataset contendo todos os exemplos já classificados que serão utilizados para gerar um modelo capaz de predizer um novo rotulo a uma frase."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./datasets/sentimentos.csv')"
   ]
  },
  {
   "source": [
    "## View Data\n",
    "\n",
    "Aqui vamos visualizar 10 exemplos de textos e sua classificação."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                 Texto Sentimento\n",
       "115                                 que banheiro porco       nojo\n",
       "313                           a noite e muito perigosa       medo\n",
       "335                       tirei ferias e fui despedido      raiva\n",
       "320  seu políticos usam suas forças para afugentar ...       medo\n",
       "751        nossa que alto aqui, eu nao gosto de altura       medo\n",
       "42                       estou cativada pelo seu olhar    alegria\n",
       "533                       essas pessoas são esplêndida   surpresa\n",
       "602                 as pessoas não gostam do meu jeito   tristeza\n",
       "149                      a indisposição me atacou hoje       nojo\n",
       "686                                   você me completa    alegria"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Texto</th>\n      <th>Sentimento</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>115</th>\n      <td>que banheiro porco</td>\n      <td>nojo</td>\n    </tr>\n    <tr>\n      <th>313</th>\n      <td>a noite e muito perigosa</td>\n      <td>medo</td>\n    </tr>\n    <tr>\n      <th>335</th>\n      <td>tirei ferias e fui despedido</td>\n      <td>raiva</td>\n    </tr>\n    <tr>\n      <th>320</th>\n      <td>seu políticos usam suas forças para afugentar ...</td>\n      <td>medo</td>\n    </tr>\n    <tr>\n      <th>751</th>\n      <td>nossa que alto aqui, eu nao gosto de altura</td>\n      <td>medo</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>estou cativada pelo seu olhar</td>\n      <td>alegria</td>\n    </tr>\n    <tr>\n      <th>533</th>\n      <td>essas pessoas são esplêndida</td>\n      <td>surpresa</td>\n    </tr>\n    <tr>\n      <th>602</th>\n      <td>as pessoas não gostam do meu jeito</td>\n      <td>tristeza</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>a indisposição me atacou hoje</td>\n      <td>nojo</td>\n    </tr>\n    <tr>\n      <th>686</th>\n      <td>você me completa</td>\n      <td>alegria</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "alegria     162\n",
       "medo        156\n",
       "raiva       152\n",
       "tristeza    149\n",
       "nojo        143\n",
       "surpresa    141\n",
       "Name: Sentimento, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df['Sentimento'].value_counts()"
   ]
  },
  {
   "source": [
    "Vamos carregar apenas 140 frases de cada tipo de sentimento a fim de equalizar os exemplos para evitar assim um favorecimento entre os tipos de exemplos."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alegria = df.loc[df.Sentimento == 'alegria'][0:140]\n",
    "df_medo = df.loc[df.Sentimento == 'medo'][0:140]\n",
    "df_raiva = df.loc[df.Sentimento == 'raiva'][0:140]\n",
    "df_tristeza = df.loc[df.Sentimento == 'tristeza'][0:140]\n",
    "df_nojo = df.loc[df.Sentimento == 'nojo'][0:140]\n",
    "df_surpresa = df.loc[df.Sentimento == 'surpresa'][0:140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_alegria, df_medo, df_raiva, df_tristeza, df_nojo, df_surpresa], ignore_index=True, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "raiva       140\n",
       "medo        140\n",
       "alegria     140\n",
       "tristeza    140\n",
       "nojo        140\n",
       "surpresa    140\n",
       "Name: Sentimento, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df.Sentimento.value_counts()"
   ]
  },
  {
   "source": [
    "## Load stop words \n",
    "\n",
    "Stop Words são palavras que não ajudam muito o modelo a conseguir realizar uma predição correta, elas não trazem um grande valor para o processo de predição por isso podem ser removidas."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\angel\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['de', 'a', 'o', 'que', 'e', 'é', 'do', 'da', 'em', 'um', 'para',\n",
       "       'com', 'não', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais'],\n",
       "      dtype='<U4')"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('portuguese')\n",
    "np.transpose(stop_words[0:20])"
   ]
  },
  {
   "source": [
    "## Stemming: Removing sulfix and prefix of word\n",
    "\n",
    "Stemming é um pré-processo para remoção das variações de determinada palavra, trazendo ela a seu radical."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package rslp to\n[nltk_data]     C:\\Users\\angel\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_stemmer(text: str):\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    texts = []\n",
    "    texts = [str(stemmer.stem(word)) for word in text.split() if word not in stop_words]\n",
    "    return tuple(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('ola', 'admir', 'mund', 'novo,', 'program', 'você!!', 'eu', 'program')"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "apply_stemmer('Ola admirável mundo novo, eu programei você!! Eu sou um programador')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Sentimento                                              Texto  \\\n",
       "20     alegria                            o dia esta muito bonito   \n",
       "372      raiva                           o que você tem com isso?   \n",
       "663       nojo                         abominavelmente convencido   \n",
       "564       nojo                      bebi demais e preciso vomitar   \n",
       "113    alegria                      não precisei pagar o ingresso   \n",
       "821   surpresa                       ah! o absoluto do imaginário   \n",
       "330      raiva          meus pais não consentiram nosso casamento   \n",
       "560       nojo                                  você e abominável   \n",
       "60     alegria        e um enorme prazer ter você em nossa equipe   \n",
       "649       nojo  não sei como e a vida de um patife, mais a de ...   \n",
       "\n",
       "                                     Palavras  \n",
       "20                               (dia, bonit)  \n",
       "372                                  (isso?,)  \n",
       "663                        (abomina, convenc)  \n",
       "564               (beb, demal, precis, vomit)  \n",
       "113                    (precis, pag, ingress)  \n",
       "821                    (ah!, absolut, imagin)  \n",
       "330                       (pal, consent, cas)  \n",
       "560                                 (abomin,)  \n",
       "60                  (enorm, praz, ter, equip)  \n",
       "649  (sei, vid, patife,, hom, honest, abomin)  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentimento</th>\n      <th>Texto</th>\n      <th>Palavras</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>20</th>\n      <td>alegria</td>\n      <td>o dia esta muito bonito</td>\n      <td>(dia, bonit)</td>\n    </tr>\n    <tr>\n      <th>372</th>\n      <td>raiva</td>\n      <td>o que você tem com isso?</td>\n      <td>(isso?,)</td>\n    </tr>\n    <tr>\n      <th>663</th>\n      <td>nojo</td>\n      <td>abominavelmente convencido</td>\n      <td>(abomina, convenc)</td>\n    </tr>\n    <tr>\n      <th>564</th>\n      <td>nojo</td>\n      <td>bebi demais e preciso vomitar</td>\n      <td>(beb, demal, precis, vomit)</td>\n    </tr>\n    <tr>\n      <th>113</th>\n      <td>alegria</td>\n      <td>não precisei pagar o ingresso</td>\n      <td>(precis, pag, ingress)</td>\n    </tr>\n    <tr>\n      <th>821</th>\n      <td>surpresa</td>\n      <td>ah! o absoluto do imaginário</td>\n      <td>(ah!, absolut, imagin)</td>\n    </tr>\n    <tr>\n      <th>330</th>\n      <td>raiva</td>\n      <td>meus pais não consentiram nosso casamento</td>\n      <td>(pal, consent, cas)</td>\n    </tr>\n    <tr>\n      <th>560</th>\n      <td>nojo</td>\n      <td>você e abominável</td>\n      <td>(abomin,)</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>alegria</td>\n      <td>e um enorme prazer ter você em nossa equipe</td>\n      <td>(enorm, praz, ter, equip)</td>\n    </tr>\n    <tr>\n      <th>649</th>\n      <td>nojo</td>\n      <td>não sei como e a vida de um patife, mais a de ...</td>\n      <td>(sei, vid, patife,, hom, honest, abomin)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "df['Palavras'] = df['Texto'].apply(apply_stemmer)\n",
    "df.sample(10)"
   ]
  },
  {
   "source": [
    "## Getting words\n",
    "\n",
    "Aqui vamos obter todas as palavras já processadas de cada frase, a fim de criar um saco de palavras, ou BagOfWords como é conhecido."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for index, item in df.iterrows():\n",
    "    words.extend(item.Palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2627"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "source": [
    "## Genereting the frequency distribution\n",
    "\n",
    "Vamos gerar aqui uma distribuição de frequencia a fim de identificar quais são as palavras mais relevantes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('vou', 30),\n",
       " ('nao', 30),\n",
       " ('tão', 21),\n",
       " ('quer', 21),\n",
       " ('tod', 20),\n",
       " ('tud', 18),\n",
       " ('ser', 18),\n",
       " ('fic', 17),\n",
       " ('sint', 17),\n",
       " ('pod', 14)]"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "frequency = nltk.FreqDist(words)\n",
    "frequency.most_common(10)"
   ]
  },
  {
   "source": [
    "## Getting unique words\n",
    "\n",
    "Com base nas palavras obtidas, vamos pegar apenas as palavras que não se repetem para utiliza-las como base para criar uma matriz binaria, a fim de identificar quais palavras estão disponiveis em cada frase."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1245\n"
     ]
    }
   ],
   "source": [
    "unique_words = frequency.keys()\n",
    "print(len(unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words_to_text(text):\n",
    "    doc = None\n",
    "    if(type(text) == type(str)):\n",
    "        doc = text.split()\n",
    "    else:\n",
    "        doc = set(text)\n",
    "        \n",
    "    features = {}\n",
    "    for word in unique_words:\n",
    "        features['%s' % word] = (word in doc)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(df: pd.DataFrame):\n",
    "    itens = []\n",
    "    for i, row in df.iterrows():\n",
    "        field = (tuple(row['Palavras']), row['Sentimento'])\n",
    "        itens.append(field)\n",
    "    return itens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(('trabalh', 'agrad'), 'alegria'),\n",
       " (('gost', 'fic', 'aconcheg'), 'alegria'),\n",
       " (('fiz', 'ades', 'curs', 'hoj', 'porqu', 'gost'), 'alegria'),\n",
       " (('admir', 'muit'), 'alegria'),\n",
       " (('ador',), 'alegria')]"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "extract_data(df)[0:5]"
   ]
  },
  {
   "source": [
    "## Splitting the data frame into train and test\n",
    "\n",
    "Com a matriz binaria montada e classficada, vamos dividir o dataset em dois blocos, que serão utilizados para treinar o modelo e testar o modelo."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[['Texto', 'Palavras']], df['Sentimento'], train_size=0.85, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "medo        124\n",
       "raiva       123\n",
       "surpresa    120\n",
       "nojo        118\n",
       "tristeza    115\n",
       "alegria     114\n",
       "Name: Sentimento, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "alegria     26\n",
       "tristeza    25\n",
       "nojo        22\n",
       "surpresa    20\n",
       "raiva       17\n",
       "medo        16\n",
       "Name: Sentimento, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Sentimento'] = y_train"
   ]
  },
  {
   "source": [
    "## Train model\n",
    "\n",
    "Vamos agora aplicar a base de treinamento a extração das palavras para criar uma matriz binaria que será utilizada para o classificar aprender os padrões"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = nltk.classify.apply_features(extract_words_to_text, extract_data(X_train), labeled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador = nltk.NaiveBayesClassifier.train(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['raiva', 'tristeza', 'medo', 'surpresa', 'alegria', 'nojo']"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "classificador.labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Most Informative Features\n                     med = True             medo : alegri =      7.1 : 1.0\n                     vou = True            raiva : surpre =      6.8 : 1.0\n                 acredit = True           surpre : triste =      6.7 : 1.0\n                   terri = True             nojo : triste =      4.9 : 1.0\n                      am = True           alegri : surpre =      4.6 : 1.0\n                     tão = True           surpre : raiva  =      4.4 : 1.0\n                     nao = True             medo : nojo   =      4.4 : 1.0\n                     ser = True             medo : raiva  =      4.3 : 1.0\n                    quer = True            raiva : surpre =      4.2 : 1.0\n                    real = True           surpre : triste =      4.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classificador.show_most_informative_features(10)"
   ]
  },
  {
   "source": [
    "## Evalueting model\n",
    "\n",
    "Com base no modelo aprendido com a base de treinamento podemos avaliar o modelo e verificar a sua acurácia na predição dos dados já rotulados."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Acerto: 96.08%\n"
     ]
    }
   ],
   "source": [
    "print(f'Acerto: {round(nltk.classify.accuracy(classificador, data) * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_metric(data) -> []:\n",
    "    erros = []\n",
    "    for (words, target) in data:\n",
    "        result = classificador.classify(words)\n",
    "        if result != target:\n",
    "            erros.append((target, result, words))\n",
    "    print(f'Erros: {(round(len(erros) / len(data) * 100,2))} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Erros: 3.92 %\n"
     ]
    }
   ],
   "source": [
    "error_metric(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics import ConfusionMatrix\n",
    "\n",
    "def view_confusion_matrix(data):\n",
    "    y = []\n",
    "    pred = []\n",
    "    for (word, target) in data:\n",
    "        result = classificador.classify(word)\n",
    "        y.append(target)\n",
    "        pred.append(result)\n",
    "\n",
    "    matriz = ConfusionMatrix(y, pred)\n",
    "    print(matriz)"
   ]
  },
  {
   "source": [
    "A matriz de confução nos mostra como cada registro foi classificado."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "         |                   s   t |\n         |   a               u   r |\n         |   l               r   i |\n         |   e           r   p   s |\n         |   g   m   n   a   r   t |\n         |   r   e   o   i   e   e |\n         |   i   d   j   v   s   z |\n         |   a   o   o   a   a   a |\n---------+-------------------------+\n alegria |<111>  .   .   1   2   . |\n    medo |   1<116>  2   3   1   1 |\n    nojo |   .   .<114>  2   1   1 |\n   raiva |   .   2   1<120>  .   . |\nsurpresa |   .   1   .   .<119>  . |\ntristeza |   2   3   .   3   1<106>|\n---------+-------------------------+\n(row = reference; col = test)\n\n"
     ]
    }
   ],
   "source": [
    "view_confusion_matrix(data)"
   ]
  },
  {
   "source": [
    "## Teste model\n",
    "\n",
    "Vamos agora avaliar o modelo criado com a base de testes a fim de validar o quao bem esse modelo seria se estivesse em um ambiente produtivo."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['Sentimento'] = y_test\n",
    "data_test = nltk.classify.apply_features(extract_words_to_text, extract_data(X_test), labeled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Acerto: 44.44%\n"
     ]
    }
   ],
   "source": [
    "print(f'Acerto: {round(nltk.classify.accuracy(classificador, data_test) * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Erros: 55.56 %\n"
     ]
    }
   ],
   "source": [
    "error_metric(data_test)"
   ]
  },
  {
   "source": [
    "Matriz de confusão sobre os dados que foram utilizados para o teste"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "         |              s  t |\n         |  a           u  r |\n         |  l           r  i |\n         |  e        r  p  s |\n         |  g  m  n  a  r  t |\n         |  r  e  o  i  e  e |\n         |  i  d  j  v  s  z |\n         |  a  o  o  a  a  a |\n---------+-------------------+\n alegria |<15> 5  .  2  2  2 |\n    medo |  . <6> .  2  3  5 |\n    nojo |  5  1 <9> 2  2  3 |\n   raiva |  2  3  2 <8> 2  . |\nsurpresa |  6  .  1  4 <8> 1 |\ntristeza |  4  2  1  6  2<10>|\n---------+-------------------+\n(row = reference; col = test)\n\n"
     ]
    }
   ],
   "source": [
    "view_confusion_matrix(data_test)"
   ]
  },
  {
   "source": [
    "Vamos criar um bloco de código que será utilizado para predizer agora as novas frases"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_test(text):\n",
    "    text = apply_stemmer(text)\n",
    "    novo = extract_words_to_text(text)\n",
    "\n",
    "    result = classificador.classify(novo)\n",
    "    print('Predicação: %s' % result)\n",
    "\n",
    "    print()\n",
    "    distribuicao = classificador.prob_classify(novo)\n",
    "    for clas in distribuicao.samples():\n",
    "        print('%s: %f' % (clas, distribuicao.prob(clas)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predicação: medo\n\nraiva: 0.210226\ntristeza: 0.044344\nmedo: 0.525327\nsurpresa: 0.048977\nalegria: 0.024613\nnojo: 0.146512\n"
     ]
    }
   ],
   "source": [
    "test = 'Eu vou ser pai!!!'\n",
    "predict_test(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predicação: surpresa\n\nraiva: 0.273349\ntristeza: 0.085567\nmedo: 0.168748\nsurpresa: 0.286206\nalegria: 0.101733\nnojo: 0.084396\n"
     ]
    }
   ],
   "source": [
    "test = 'Fui assaltado ontem'\n",
    "predict_test(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predicação: tristeza\n\nraiva: 0.137687\ntristeza: 0.368931\nmedo: 0.085693\nsurpresa: 0.140632\nalegria: 0.143689\nnojo: 0.123368\n"
     ]
    }
   ],
   "source": [
    "test = 'Ganhei na mega sena'\n",
    "predict_test(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predicação: alegria\n\nraiva: 0.012283\ntristeza: 0.037629\nmedo: 0.022750\nsurpresa: 0.120597\nalegria: 0.770575\nnojo: 0.036167\n"
     ]
    }
   ],
   "source": [
    "test = 'Estou namorando uma gata linda'\n",
    "predict_test(test)"
   ]
  }
 ]
}