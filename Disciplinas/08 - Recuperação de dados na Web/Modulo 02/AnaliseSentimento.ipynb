{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Analise de sentimento"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "source": [
    "##  Read csv file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./datasets/sentimentos.csv')"
   ]
  },
  {
   "source": [
    "## View Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                Texto Sentimento\n",
       "437                            uau que noticia bacana   surpresa\n",
       "685              esta comida me parece muito atraente    alegria\n",
       "780           e abominável o que fazem com os animais       medo\n",
       "606                  estou sem dinheiro para a comida   tristeza\n",
       "851                     que bela surpresa você me fez   surpresa\n",
       "298  eu te entrego o dinheiro, por favor não me mate!       medo\n",
       "154               suas bobagens estão nos incomodando       nojo\n",
       "487                estamos seguindo o caminho errado!   surpresa\n",
       "498                         isso e realmente chocante   surpresa\n",
       "627                           só me resta a esperança   tristeza"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Texto</th>\n      <th>Sentimento</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>437</th>\n      <td>uau que noticia bacana</td>\n      <td>surpresa</td>\n    </tr>\n    <tr>\n      <th>685</th>\n      <td>esta comida me parece muito atraente</td>\n      <td>alegria</td>\n    </tr>\n    <tr>\n      <th>780</th>\n      <td>e abominável o que fazem com os animais</td>\n      <td>medo</td>\n    </tr>\n    <tr>\n      <th>606</th>\n      <td>estou sem dinheiro para a comida</td>\n      <td>tristeza</td>\n    </tr>\n    <tr>\n      <th>851</th>\n      <td>que bela surpresa você me fez</td>\n      <td>surpresa</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>eu te entrego o dinheiro, por favor não me mate!</td>\n      <td>medo</td>\n    </tr>\n    <tr>\n      <th>154</th>\n      <td>suas bobagens estão nos incomodando</td>\n      <td>nojo</td>\n    </tr>\n    <tr>\n      <th>487</th>\n      <td>estamos seguindo o caminho errado!</td>\n      <td>surpresa</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>isso e realmente chocante</td>\n      <td>surpresa</td>\n    </tr>\n    <tr>\n      <th>627</th>\n      <td>só me resta a esperança</td>\n      <td>tristeza</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "alegria     162\n",
       "medo        156\n",
       "raiva       152\n",
       "tristeza    149\n",
       "nojo        143\n",
       "surpresa    141\n",
       "Name: Sentimento, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df['Sentimento'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alegria = df.loc[df.Sentimento == 'alegria'][0:140]\n",
    "df_medo = df.loc[df.Sentimento == 'medo'][0:140]\n",
    "df_raiva = df.loc[df.Sentimento == 'raiva'][0:140]\n",
    "df_tristeza = df.loc[df.Sentimento == 'tristeza'][0:140]\n",
    "df_nojo = df.loc[df.Sentimento == 'nojo'][0:140]\n",
    "df_surpresa = df.loc[df.Sentimento == 'surpresa'][0:140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Texto         140\n",
       "Sentimento    140\n",
       "Palavras      140\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": []
  },
  {
   "source": [
    "## Load stop words "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "source": [
    "## Stemming: Removing sulfix and prefix of word"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_stemmer(text: str):\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    texts = []\n",
    "    texts = [str(stemmer.stem(word)) for word in text.split() if word not in stop_words]\n",
    "    return tuple(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('ola', 'admir', 'mund', 'novo,', 'program', 'você!!', 'eu', 'program')"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "apply_stemmer('Ola admirável mundo novo, eu programei você!! Eu sou um programador')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                 Texto Sentimento  \\\n",
       "193                            que criança mal educada       nojo   \n",
       "741             vamos alarmar a todos sobre a situação       medo   \n",
       "605                     ele não gostou da minha comida   tristeza   \n",
       "413               eu faco dieta e constinuo engordando      raiva   \n",
       "778  fui notificado e estou com medo de perde a gua...       medo   \n",
       "539                               não me deixe sozinha   tristeza   \n",
       "375                           seu descaso e frustrante      raiva   \n",
       "552                             acabaram minhas ferias   tristeza   \n",
       "501        nossa, que top esse filme!, eu nao esperava   surpresa   \n",
       "168                           esse perfume e enjoativo       nojo   \n",
       "\n",
       "                               Palavras  \n",
       "193                 (crianç, mal, educ)  \n",
       "741       (vam, alarm, tod, sobr, situ)  \n",
       "605                         (gost, com)  \n",
       "413       (fac, diet, constinu, engord)  \n",
       "778   (notific, med, perd, guard, filh)  \n",
       "539                          (deix, so)  \n",
       "375                    (descas, frustr)  \n",
       "552                         (acab, fer)  \n",
       "501  (nossa,, top, filme!,, nao, esper)  \n",
       "168                      (perfum, enjo)  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Texto</th>\n      <th>Sentimento</th>\n      <th>Palavras</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>193</th>\n      <td>que criança mal educada</td>\n      <td>nojo</td>\n      <td>(crianç, mal, educ)</td>\n    </tr>\n    <tr>\n      <th>741</th>\n      <td>vamos alarmar a todos sobre a situação</td>\n      <td>medo</td>\n      <td>(vam, alarm, tod, sobr, situ)</td>\n    </tr>\n    <tr>\n      <th>605</th>\n      <td>ele não gostou da minha comida</td>\n      <td>tristeza</td>\n      <td>(gost, com)</td>\n    </tr>\n    <tr>\n      <th>413</th>\n      <td>eu faco dieta e constinuo engordando</td>\n      <td>raiva</td>\n      <td>(fac, diet, constinu, engord)</td>\n    </tr>\n    <tr>\n      <th>778</th>\n      <td>fui notificado e estou com medo de perde a gua...</td>\n      <td>medo</td>\n      <td>(notific, med, perd, guard, filh)</td>\n    </tr>\n    <tr>\n      <th>539</th>\n      <td>não me deixe sozinha</td>\n      <td>tristeza</td>\n      <td>(deix, so)</td>\n    </tr>\n    <tr>\n      <th>375</th>\n      <td>seu descaso e frustrante</td>\n      <td>raiva</td>\n      <td>(descas, frustr)</td>\n    </tr>\n    <tr>\n      <th>552</th>\n      <td>acabaram minhas ferias</td>\n      <td>tristeza</td>\n      <td>(acab, fer)</td>\n    </tr>\n    <tr>\n      <th>501</th>\n      <td>nossa, que top esse filme!, eu nao esperava</td>\n      <td>surpresa</td>\n      <td>(nossa,, top, filme!,, nao, esper)</td>\n    </tr>\n    <tr>\n      <th>168</th>\n      <td>esse perfume e enjoativo</td>\n      <td>nojo</td>\n      <td>(perfum, enjo)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "df['Palavras'] = df['Texto'].apply(apply_stemmer)\n",
    "df.sample(10)"
   ]
  },
  {
   "source": [
    "## Getting words"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for index, item in df.iterrows():\n",
    "    words.extend(item.Palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2797"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "source": [
    "## Genereting the frequency distribution"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('vou', 32),\n",
       " ('nao', 30),\n",
       " ('quer', 23),\n",
       " ('tão', 22),\n",
       " ('tod', 20),\n",
       " ('ser', 20),\n",
       " ('sint', 19),\n",
       " ('tud', 19),\n",
       " ('pod', 18),\n",
       " ('fic', 17)]"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "frequency = nltk.FreqDist(words)\n",
    "frequency.most_common(10)"
   ]
  },
  {
   "source": [
    "## Getting unique words"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1290\n"
     ]
    }
   ],
   "source": [
    "unique_words = frequency.keys()\n",
    "print(len(unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words_to_text(text):\n",
    "    doc = None\n",
    "    if(type(text) == type(str)):\n",
    "        doc = text.split()\n",
    "    else:\n",
    "        doc = set(text)\n",
    "        \n",
    "    features = {}\n",
    "    for word in unique_words:\n",
    "        features['%s' % word] = (word in doc)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(df: pd.DataFrame):\n",
    "    itens = []\n",
    "    for i, row in df.iterrows():\n",
    "        field = (tuple(row['Palavras']), row['Sentimento'])\n",
    "        itens.append(field)\n",
    "    return itens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(('trabalh', 'agrad'), 'alegria'),\n",
       " (('gost', 'fic', 'aconcheg'), 'alegria'),\n",
       " (('fiz', 'ades', 'curs', 'hoj', 'porqu', 'gost'), 'alegria'),\n",
       " (('admir', 'muit'), 'alegria'),\n",
       " (('ador',), 'alegria')]"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "extract_data(df)[0:5]"
   ]
  },
  {
   "source": [
    "## Splitting the data frame into train and test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['Texto', 'Palavras']], df['Sentimento'], train_size=0.85, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "alegria     140\n",
       "raiva       133\n",
       "medo        127\n",
       "nojo        123\n",
       "surpresa    122\n",
       "tristeza    122\n",
       "Name: Sentimento, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "medo        29\n",
       "tristeza    27\n",
       "alegria     22\n",
       "nojo        20\n",
       "surpresa    19\n",
       "raiva       19\n",
       "Name: Sentimento, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Sentimento'] = y_train"
   ]
  },
  {
   "source": [
    "## Train model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = nltk.classify.apply_features(extract_words_to_text, extract_data(X_train), labeled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador = nltk.NaiveBayesClassifier.train(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['nojo', 'tristeza', 'medo', 'raiva', 'alegria', 'surpresa']"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "classificador.labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Most Informative Features\n                     med = True             medo : alegri =      9.9 : 1.0\n                     vou = True            raiva : triste =      8.9 : 1.0\n                    real = True           surpre : alegri =      5.7 : 1.0\n                     ser = True             medo : raiva  =      5.2 : 1.0\n                 depress = True           triste : medo   =      5.2 : 1.0\n                      am = True           alegri : nojo   =      5.0 : 1.0\n                    pass = True            raiva : alegri =      4.6 : 1.0\n                    sint = True           triste : medo   =      4.5 : 1.0\n                   notic = True           surpre : alegri =      4.2 : 1.0\n                     vid = True           triste : alegri =      4.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classificador.show_most_informative_features(10)"
   ]
  },
  {
   "source": [
    "## Evalueting model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9452411994784876\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classificador, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_metric(data) -> []:\n",
    "    erros = []\n",
    "    for (words, target) in data:\n",
    "        result = classificador.classify(words)\n",
    "        if result != target:\n",
    "            erros.append((target, result, words))\n",
    "    print(f'Erros: {(round(len(erros) / len(data) * 100,2))} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Erros: 5.48 %\n"
     ]
    }
   ],
   "source": [
    "error_metric(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics import ConfusionMatrix\n",
    "\n",
    "def view_confusion_matrix(data):\n",
    "    y = []\n",
    "    pred = []\n",
    "    for (word, target) in data:\n",
    "        result = classificador.classify(word)\n",
    "        y.append(target)\n",
    "        pred.append(result)\n",
    "\n",
    "    matriz = ConfusionMatrix(y, pred)\n",
    "    print(matriz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "         |                   s   t |\n         |   a               u   r |\n         |   l               r   i |\n         |   e           r   p   s |\n         |   g   m   n   a   r   t |\n         |   r   e   o   i   e   e |\n         |   i   d   j   v   s   z |\n         |   a   o   o   a   a   a |\n---------+-------------------------+\n alegria |<139>  .   .   1   .   . |\n    medo |   8<112>  1   4   1   1 |\n    nojo |   1   .<121>  .   1   . |\n   raiva |   5   .   2<124>  1   1 |\nsurpresa |   4   .   .   1<116>  1 |\ntristeza |   3   .   1   4   1<113>|\n---------+-------------------------+\n(row = reference; col = test)\n\n"
     ]
    }
   ],
   "source": [
    "view_confusion_matrix(data)"
   ]
  },
  {
   "source": [
    "## Teste model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['Sentimento'] = y_test\n",
    "data_test = nltk.classify.apply_features(extract_words_to_text, extract_data(X_test), labeled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.38235294117647056\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classificador, data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Erros: 61.76 %\n"
     ]
    }
   ],
   "source": [
    "error_metric(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "         |              s  t |\n         |  a           u  r |\n         |  l           r  i |\n         |  e        r  p  s |\n         |  g  m  n  a  r  t |\n         |  r  e  o  i  e  e |\n         |  i  d  j  v  s  z |\n         |  a  o  o  a  a  a |\n---------+-------------------+\n alegria |<14> 1  .  3  2  2 |\n    medo | 13 <3> 2  3  5  3 |\n    nojo |  1  3 <9> 4  2  1 |\n   raiva |  9  .  . <4> .  6 |\nsurpresa |  5  1  1  2<10> . |\ntristeza |  4  2  2  5  2<12>|\n---------+-------------------+\n(row = reference; col = test)\n\n"
     ]
    }
   ],
   "source": [
    "view_confusion_matrix(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "nojo: 0.134556\ntristeza: 0.129054\nmedo: 0.080013\nraiva: 0.176868\nalegria: 0.356048\nsurpresa: 0.123461\n"
     ]
    }
   ],
   "source": [
    "test = 'Que merda, não passei.'\n",
    "test = apply_stemmer(test)\n",
    "novo = extract_words_to_text(test)\n",
    "distribuicao = classificador.prob_classify(novo)\n",
    "for clas in distribuicao.samples():\n",
    "    print('%s: %f' % (clas, distribuicao.prob(clas)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'dois', 'um'}"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "y = ('um', 'dois')\n",
    "set(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}