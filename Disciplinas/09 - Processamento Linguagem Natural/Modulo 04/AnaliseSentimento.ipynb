{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "0204325da5c4cfa76f1d74fd4e08d4b1d3f65652f0a93ad9c8a4a57490d8536c"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "#  Analise de sentimentos\n",
    "\n",
    "* Análise de sentimentos com algoritmo de VADER\n",
    "\n",
    "* Utilizando TF-IDF para cálculo de similaridade (base para criação de um chatbot).\n",
    "\n",
    "* Nós podemos usar os tokens extraídos das palavra, n-gramse as técninas que vimos até o momento para construir um sistema de análise de sentimentos (uma das principais aplicações em NLP).\n",
    "\n",
    "* A análise de sentimentos permite saber, por exemplo, o que as pessoas pensam sobre determinada entidade (produto, musica, game, filme, etc).\n",
    "\n",
    "* A maioria dos produtos são classificados por estrelas (e-commerce por exemplo)\n",
    "\n",
    "* No entanto, um forma mais natural é usar os comentários (muitas das plataformas de e-commerce possuem) em linguagem natural.\n",
    "\n",
    "* O grande problema no uso de comentários para saber o feedback de um produto é que será necessário ler os comentários para uma análise.\n",
    "\n",
    "* Um piepline de NLP pode processar uma grande quantidade de feedback do usuário de maneira rápida e objetiva, eleminando um possível viés que a análise humana possa ter.\n",
    "\n",
    "* E um pipeline de NLP pode gerar uma classificação numérica sobre o comentário (negativo ou positivo).\n",
    "\n",
    "* Outra aplicação é a análise de mensagem indesejada e inadequadas para determinado contexto.\n",
    "\n",
    "* Um chatbot, por exemplo, pode ser capaz de medir o sentimento nas mensagens de chat processadas para responder adquadamente (ou analisar suas próprias mensagens antes de responder).\n",
    "\n",
    "* Suponha que o objetivo seja medir o quão positivo um texto pode ser (texto sobre um determinado produto).\n",
    "\n",
    "* Este algoritmo pode produzir um número de ponto flutuante entre +1 e -1 (+1 para texto com sentimentos positivos como: \"Absolutamente perfeito! Adoro! :-)\"\"...\n",
    "\n",
    "* E -1 para texto com sentimento negativos como \"Horrível!!!, Completamente inútil :(\"."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "* Existem duas abordagens para análise de sentimentos:\n",
    "\n",
    "    * Um algoritmo de regras compostas por um ser humano.\n",
    "\n",
    "    * Um modelo de machine learning treinado com dados produzidos por computador.\n",
    "\n",
    "\n",
    "* A primeira abordagem usa regras criadas por seres humanos para medir sentimentos.\n",
    "\n",
    "* Uma abordagem comum é encontrar palavras-chaves no texto e mapear cada uma para pontuações ou pesos numéricos em um dicionário, por exemplo.\n",
    "\n",
    "* Neste caso, usamos tokenização, stems, lemas ou n-grams no dicionário, em vez de apenas palavras.\n",
    "\n",
    "* A \"regra\" do algoritmo seria somar essas pontuações para cada palavra-chave em um documento encontradas no dicionário de pontuações.\n",
    "\n",
    "* Podemos usar o algoritmos VADER (sklearn) para produzir este dicionário de pontuações."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Algoritmo de Vader\n",
    "\n",
    "* Criado por Hutto E Gilbert na GA Tech, o VADER (valence Aware Dictionary For sEntiment Reasoning) é um dos primeiros algoritmos baseados em regras.\n",
    "\n",
    "* Muitos dos pacotes de NLP (NLTK) implementam este algoritmo.\n",
    "\n",
    "* Para instalação em python: \"pip install vaderSentiment\""
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: vaderSentiment in d:\\angel\\anaconda3\\lib\\site-packages (3.3.2)\nRequirement already satisfied: requests in d:\\angel\\anaconda3\\lib\\site-packages (from vaderSentiment) (2.24.0)\nRequirement already satisfied: chardet<4,>=3.0.2 in d:\\angel\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in d:\\angel\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2020.6.20)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in d:\\angel\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (1.25.11)\nRequirement already satisfied: idna<3,>=2.5 in d:\\angel\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ".1, 'stupid': -2.4, 'stupider': -2.5, 'stupidest': -2.4, 'stupidities': -2.0, 'stupidity': -1.9, 'stupidly': -2.0, 'stupidness': -1.7, 'stupidnesses': -2.6, 'stupids': -2.3, 'stutter': -1.0, 'stuttered': -0.9, 'stutterer': -1.0, 'stutterers': -1.1, 'stuttering': -1.3, 'stutters': -1.0, 'suave': 2.0, 'submissive': -1.3, 'submissively': -1.0, 'submissiveness': -0.7, 'substantial': 0.8, 'subversive': -0.9, 'succeed': 2.2, 'succeeded': 1.8, 'succeeder': 1.2, 'succeeders': 1.3, 'succeeding': 2.2, 'succeeds': 2.2, 'success': 2.7, 'successes': 2.6, 'successful': 2.8, 'successfully': 2.2, 'successfulness': 2.7, 'succession': 0.8, 'successional': 0.9, 'successionally': 1.1, 'successions': 0.1, 'successive': 1.1, 'successively': 0.9, 'successiveness': 1.0, 'successor': 0.9, 'successors': 1.1, 'suck': -1.9, 'sucked': -2.0, 'sucker': -2.4, 'suckered': -2.0, 'suckering': -2.1, 'suckers': -2.3, 'sucks': -1.5, 'sucky': -1.9, 'suffer': -2.5, 'suffered': -2.2, 'sufferer': -2.0, 'sufferers': -2.4, 'suffering': -2.1, 'suffers': -2.1, 'suicidal': -3.5, 'suicide': -3.5, 'suing': -1.1, 'sulking': -1.5, 'sulky': -0.8, 'sullen': -1.7, 'sunnier': 2.3, 'sunniest': 2.4, 'sunny': 1.8, 'sunshine': 2.2, 'sunshiny': 1.9, 'super': 2.9, 'superb': 3.1, 'superior': 2.5, 'superiorities': 0.8, 'superiority': 1.4, 'superiorly': 2.2, 'superiors': 1.0, 'support': 1.7, 'supported': 1.3, 'supporter': 1.1, 'supporters': 1.9, 'supporting': 1.9, 'supportive': 1.2, 'supportiveness': 1.5, 'supports': 1.5, 'supremacies': 0.8, 'supremacist': 0.5, 'supremacists': -1.0, 'supremacy': 0.2, 'suprematists': 0.4, 'supreme': 2.6, 'supremely': 2.7, 'supremeness': 2.3, 'supremer': 2.3, 'supremest': 2.2, 'supremo': 1.9, 'supremos': 1.3, 'sure': 1.3, 'surefire': 1.0, 'surefooted': 1.9, 'surefootedly': 1.6, 'surefootedness': 1.5, 'surely': 1.9, 'sureness': 2.0, 'surer': 1.2, 'surest': 1.3, 'sureties': 1.3, 'surety': 1.0, 'suretyship': -0.1, 'suretyships': 0.4, 'surprisal': 1.5, 'surprisals': 0.7, 'surprise': 1.1, 'surprised': 0.9, 'surpriser': 0.6, 'surprisers': 0.3, 'surprises': 0.9, 'surprising': 1.1, 'surprisingly': 1.2, 'survived': 2.3, 'surviving': 1.2, 'survivor': 1.5, 'suspect': -1.2, 'suspected': -0.9, 'suspecting': -0.7, 'suspects': -1.4, 'suspend': -1.3, 'suspended': -2.1, 'suspicion': -1.6, 'suspicions': -1.5, 'suspicious': -1.5, 'suspiciously': -1.7, 'suspiciousness': -1.2, 'sux': -1.5, 'swear': -0.2, 'swearing': -1.0, 'swears': 0.2, 'sweet': 2.0, 'sweet<3': 3.0, 'sweetheart': 3.3, 'sweethearts': 2.8, 'sweetie': 2.2, 'sweeties': 2.1, 'sweetly': 2.1, 'sweetness': 2.2, 'sweets': 2.2, 'swift': 0.8, 'swiftly': 1.2, 'swindle': -2.4, 'swindles': -1.5, 'swindling': -2.0, 'sympathetic': 2.3, 'sympathy': 1.5, 'talent': 1.8, 'talented': 2.3, 'talentless': -1.6, 'talents': 2.0, 'tantrum': -1.8, 'tantrums': -1.5, 'tard': -2.5, 'tears': -0.9, 'teas': 0.3, 'tease': -1.3, 'teased': -1.2, 'teasel': -0.1, 'teaseled': -0.8, 'teaseler': -0.8, 'teaselers': -1.2, 'teaseling': -0.4, 'teaselled': -0.4, 'teaselling': -0.2, 'teasels': -0.1, 'teaser': -1.0, 'teasers': -0.7, 'teases': -1.2, 'teashops': 0.2, 'teasing': -0.3, 'teasingly': -0.4, 'teaspoon': 0.2, 'teaspoonful': 0.2, 'teaspoonfuls': 0.4, 'teaspoons': 0.5, 'teaspoonsful': 0.3, 'temper': -1.8, 'tempers': -1.3, 'tendered': 0.5, 'tenderer': 0.6, 'tenderers': 1.2, 'tenderest': 1.4, 'tenderfeet': -0.4, 'tenderfoot': -0.1, 'tenderfoots': -0.5, 'tenderhearted': 1.5, 'tenderheartedly': 2.7, 'tenderheartedness': 0.7, 'tenderheartednesses': 2.8, 'tendering': 0.6, 'tenderization': 0.2, 'tenderize': 0.1, 'tenderized': 0.1, 'tenderizer': 0.4, 'tenderizes': 0.3, 'tenderizing': 0.3, 'tenderloin': -0.2, 'tenderloins': 0.4, 'tenderly': 1.8, 'tenderness': 1.8, 'tendernesses': 0.9, 'tenderometer': 0.2, 'tenderometers': 0.2, 'tenders': 0.6, 'tense': -1.4, 'tensed': -1.0, 'tensely': -1.2, 'tenseness': -1.5, 'tenser': -1.5, 'tenses': -0.9, 'tensest': -1.2, 'tensing': -1.0, 'tension': -1.3, 'tensional': -0.8, 'tensioned': -0.4, 'tensioner': -1.6, 'tensioners': -0.9, 'tensioning': -1.4, 'tensionless': 0.6, 'tensions': -1.7, 'terrible': -2.1, 'terribleness': -1.9, 'terriblenesses': -2.6, 'terribly': -2.6, 'terrific': 2.1, 'terrifically': 1.7, 'terrified': -3.0, 'terrifies': -2.6, 'terrify': -2.3, 'terrifying': -2.7, 'terror': -2.4, 'terrorise': -3.1, 'terrorised': -3.3, 'terrorises': -3.3, 'terrorising': -3.0, 'terrorism': -3.6, 'terrorisms': -3.2, 'terrorist': -3.7, 'terroristic': -3.3, 'terrorists': -3.1, 'terrorization': -2.7, 'terrorize': -3.3, 'terrorized': -3.1, 'terrorizes': -3.1, 'terrorizing': -3.0, 'terrorless': 0.9, 'terrors': -2.6, 'thank': 1.5, 'thanked': 1.9, 'thankful': 2.7, 'thankfuller': 1.9, 'thankfullest': 2.0, 'thankfully': 1.8, 'thankfulness': 2.1, 'thanks': 1.9, 'thief': -2.4, 'thieve': -2.2, 'thieved': -1.4, 'thieveries': -2.1, 'thievery': -2.0, 'thieves': -2.3, 'thorny': -1.1, 'thoughtful': 1.6, 'thoughtfully': 1.7, 'thoughtfulness': 1.9, 'thoughtless': -2.0, 'threat': -2.4, 'threaten': -1.6, 'threatened': -2.0, 'threatener': -1.4, 'threateners': -1.8, 'threatening': -2.4, 'threateningly': -2.2, 'threatens': -1.6, 'threating': -2.0, 'threats': -1.8, 'thrill': 1.5, 'thrilled': 1.9, 'thriller': 0.4, 'thrillers': 0.1, 'thrilling': 2.1, 'thrillingly': 2.0, 'thrills': 1.5, 'thwarted': -0.1, 'thwarting': -0.7, 'thwarts': -0.4, 'ticked': -1.8, 'timid': -1.0, 'timider': -1.0, 'timidest': -0.9, 'timidities': -0.7, 'timidity': -1.3, 'timidly': -0.7, 'timidness': -1.0, 'timorous': -0.8, 'tired': -1.9, 'tits': -0.9, 'tolerance': 1.2, 'tolerances': 0.3, 'tolerant': 1.1, 'tolerantly': 0.4, 'toothless': -1.4, 'top': 0.8, 'tops': 2.3, 'torn': -1.0, 'torture': -2.9, 'tortured': -2.6, 'torturer': -2.3, 'torturers': -3.5, 'tortures': -2.5, 'torturing': -3.0, 'torturous': -2.7, 'torturously': -2.2, 'totalitarian': -2.1, 'totalitarianism': -2.7, 'tough': -0.5, 'toughed': 0.7, 'toughen': 0.1, 'toughened': 0.1, 'toughening': 0.9, 'toughens': -0.2, 'tougher': 0.7, 'toughest': -0.3, 'toughie': -0.7, 'toughies': -0.6, 'toughing': -0.5, 'toughish': -1.0, 'toughly': -1.1, 'toughness': -0.2, 'toughnesses': 0.3, 'toughs': -0.8, 'toughy': -0.5, 'tout': -0.5, 'touted': -0.2, 'touting': -0.7, 'touts': -0.1, 'tragedian': -0.5, 'tragedians': -1.0, 'tragedienne': -0.4, 'tragediennes': -1.4, 'tragedies': -1.9, 'tragedy': -3.4, 'tragic': -2.0, 'tragical': -2.4, 'tragically': -2.7, 'tragicomedy': 0.2, 'tragicomic': -0.2, 'tragics': -2.2, 'tranquil': 0.2, 'tranquiler': 1.9, 'tranquilest': 1.6, 'tranquilities': 1.5, 'tranquility': 1.8, 'tranquilize': 0.3, 'tranquilized': -0.2, 'tranquilizer': -0.1, 'tranquilizers': -0.4, 'tranquilizes': -0.1, 'tranquilizing': -0.5, 'tranquillest': 0.8, 'tranquillities': 0.5, 'tranquillity': 1.8, 'tranquillized': -0.2, 'tranquillizer': -0.1, 'tranquillizers': -0.2, 'tranquillizes': 0.1, 'tranquillizing': 0.8, 'tranquilly': 1.2, 'tranquilness': 1.5, 'trap': -1.3, 'trapped': -2.4, 'trauma': -1.8, 'traumas': -2.2, 'traumata': -1.7, 'traumatic': -2.7, 'traumatically': -2.8, 'traumatise': -2.8, 'traumatised': -2.4, 'traumatises': -2.2, 'traumatising': -1.9, 'traumatism': -2.4, 'traumatization': -3.0, 'traumatizations': -2.2, 'traumatize': -2.4, 'traumatized': -1.7, 'traumatizes': -1.4, 'traumatizing': -2.3, 'travesty': -2.7, 'treason': -1.9, 'treasonous': -2.7, 'treasurable': 2.5, 'treasure': 1.2, 'treasured': 2.6, 'treasurer': 0.5, 'treasurers': 0.4, 'treasurership': 0.4, 'treasurerships': 1.2, 'treasures': 1.8, 'treasuries': 0.9, 'treasuring': 2.1, 'treasury': 0.8, 'treat': 1.7, 'tremble': -1.1, 'trembled': -1.1, 'trembler': -0.6, 'tremblers': -1.0, 'trembles': -0.1, 'trembling': -1.5, 'trembly': -1.2, 'tremulous': -1.0, 'trick': -0.2, 'tricked': -0.6, 'tricker': -0.9, 'trickeries': -1.2, 'trickers': -1.4, 'trickery': -1.1, 'trickie': -0.4, 'trickier': -0.7, 'trickiest': -1.2, 'trickily': -0.8, 'trickiness': -1.2, 'trickinesses': -0.4, 'tricking': 0.1, 'trickish': -1.0, 'trickishly': -0.7, 'trickishness': -0.4, 'trickled': 0.1, 'trickledown': -0.7, 'trickles': 0.2, 'trickling': -0.2, 'trickly': -0.3, 'tricks': -0.5, 'tricksier': -0.5, 'tricksiness': -1.0, 'trickster': -0.9, 'tricksters': -1.3, 'tricksy': -0.8, 'tricky': -0.6, 'trite': -0.8, 'triumph': 2.1, 'triumphal': 2.0, 'triumphalisms': 1.9, 'triumphalist': 0.5, 'triumphalists': 0.9, 'triumphant': 2.4, 'triumphantly': 2.3, 'triumphed': 2.2, 'triumphing': 2.3, 'triumphs': 2.0, 'trivial': -0.1, 'trivialise': -0.8, 'trivialised': -0.8, 'trivialises': -1.1, 'trivialising': -1.4, 'trivialities': -1.0, 'triviality': -0.5, 'trivialization': -0.9, 'trivializations': -0.7, 'trivialize': -1.1, 'trivialized': -0.6, 'trivializes': -1.0, 'trivializing': -0.6, 'trivially': 0.4, 'trivium': -0.3, 'trouble': -1.7, 'troubled': -2.0, 'troublemaker': -2.0, 'troublemakers': -2.2, 'troublemaking': -1.8, 'troubler': -1.4, 'troublers': -1.9, 'troubles': -2.0, 'troubleshoot': 0.8, 'troubleshooter': 1.0, 'troubleshooters': 0.8, 'troubleshooting': 0.7, 'troubleshoots': 0.5, 'troublesome': -2.3, 'troublesomely': -1.8, 'troublesomeness': -1.9, 'troubling': -2.5, 'troublous': -2.1, 'troublously': -2.1, 'trueness': 2.1, 'truer': 1.5, 'truest': 1.9, 'truly': 1.9, 'trust': 2.3, 'trustability': 2.1, 'trustable': 2.3, 'trustbuster': -0.5, 'trusted': 2.1, 'trustee': 1.0, 'trustees': 0.3, 'trusteeship': 0.5, 'trusteeships': 0.6, 'truster': 1.9, 'trustful': 2.1, 'trustfully': 1.5, 'trustfulness': 2.1, 'trustier': 1.3, 'trusties': 1.0, 'trustiest': 2.2, 'trustily': 1.6, 'trustiness': 1.6, 'trusting': 1.7, 'trustingly': 1.6, 'trustingness': 1.6, 'trustless': -2.3, 'trustor': 0.4, 'trustors': 1.2, 'trusts': 2.1, 'trustworthily': 2.3, 'trustworthiness': 1.8, 'trustworthy': 2.6, 'trusty': 2.2, 'truth': 1.3, 'truthful': 2.0, 'truthfully': 1.9, 'truthfulness': 1.7, 'truths': 1.8, 'tumor': -1.6, 'turmoil': -1.5, 'twat': -3.4, 'ugh': -1.8, 'uglier': -2.2, 'uglies': -2.0, 'ugliest': -2.8, 'uglification': -2.2, 'uglified': -1.5, 'uglifies': -1.8, 'uglify': -2.1, 'uglifying': -2.2, 'uglily': -2.1, 'ugliness': -2.7, 'uglinesses': -2.5, 'ugly': -2.3, 'unacceptable': -2.0, 'unappreciated': -1.7, 'unapproved': -1.4, 'unattractive': -1.9, 'unaware': -0.8, 'unbelievable': 0.8, 'unbelieving': -0.8, 'unbiased': -0.1, 'uncertain': -1.2, 'uncertainly': -1.4, 'uncertainness': -1.3, 'uncertainties': -1.4, 'uncertainty': -1.4, 'unclear': -1.0, 'uncomfortable': -1.6, 'uncomfortably': -1.7, 'uncompelling': -0.9, 'unconcerned': -0.9, 'unconfirmed': -0.5, 'uncontrollability': -1.7, 'uncontrollable': -1.5, 'uncontrollably': -1.5, 'uncontrolled': -1.0, 'unconvinced': -1.6, 'uncredited': -1.0, 'undecided': -0.9, 'underestimate': -1.2, 'underestimated': -1.1, 'underestimates': -1.1, 'undermine': -1.2, 'undermined': -1.5, 'undermines': -1.4, 'undermining': -1.5, 'undeserving': -1.9, 'undesirable': -1.9, 'unease': -1.7, 'uneasier': -1.4, 'uneasiest': -2.1, 'uneasily': -1.4, 'uneasiness': -1.6, 'uneasinesses': -1.8, 'uneasy': -1.6, 'unemployment': -1.9, 'unequal': -1.4, 'unequaled': 0.5, 'unethical': -2.3, 'unfair': -2.1, 'unfocused': -1.7, 'unfortunate': -2.0, 'unfortunately': -1.4, 'unfortunates': -1.9, 'unfriendly': -1.5, 'unfulfilled': -1.8, 'ungrateful': -2.0, 'ungratefully': -1.8, 'ungratefulness': -1.6, 'unhappier': -2.4, 'unhappiest': -2.5, 'unhappily': -1.9, 'unhappiness': -2.4, 'unhappinesses': -2.2, 'unhappy': -1.8, 'unhealthy': -2.4, 'unified': 1.6, 'unimportant': -1.3, 'unimpressed': -1.4, 'unimpressive': -1.4, 'unintelligent': -2.0, 'uninvolved': -2.2, 'uninvolving': -2.0, 'united': 1.8, 'unjust': -2.3, 'unkind': -1.6, 'unlovable': -2.7, 'unloved': -1.9, 'unlovelier': -1.9, 'unloveliest': -1.9, 'unloveliness': -2.0, 'unlovely': -2.1, 'unloving': -2.3, 'unmatched': -0.3, 'unmotivated': -1.4, 'unpleasant': -2.1, 'unprofessional': -2.3, 'unprotected': -1.5, 'unresearched': -1.1, 'unsatisfied': -1.7, 'unsavory': -1.9, 'unsecured': -1.6, 'unsettled': -1.3, 'unsophisticated': -1.2, 'unstable': -1.5, 'unstoppable': -0.8, 'unsuccessful': -1.5, 'unsuccessfully': -1.7, 'unsupported': -1.7, 'unsure': -1.0, 'unsurely': -1.3, 'untarnished': 1.6, 'unwanted': -0.9, 'unwelcome': -1.7, 'unworthy': -2.0, 'upset': -1.6, 'upsets': -1.5, 'upsetter': -1.9, 'upsetters': -2.0, 'upsetting': -2.1, 'uptight': -1.6, 'uptightness': -1.2, 'urgent': 0.8, 'useful': 1.9, 'usefully': 1.8, 'usefulness': 1.2, 'useless': -1.8, 'uselessly': -1.5, 'uselessness': -1.6, 'v.v': -2.9, 'vague': -0.4, 'vain': -1.8, 'validate': 1.5, 'validated': 0.9, 'validates': 1.4, 'validating': 1.4, 'valuable': 2.1, 'valuableness': 1.7, 'valuables': 2.1, 'valuably': 2.3, 'value': 1.4, 'valued': 1.9, 'values': 1.7, 'valuing': 1.4, 'vanity': -0.9, 'verdict': 0.6, 'verdicts': 0.3, 'vested': 0.6, 'vexation': -1.9, 'vexing': -2.0, 'vibrant': 2.4, 'vicious': -1.5, 'viciously': -1.3, 'viciousness': -2.4, 'viciousnesses': -0.6, 'victim': -1.1, 'victimhood': -2.0, 'victimhoods': -0.9, 'victimise': -1.1, 'victimised': -1.5, 'victimises': -1.2, 'victimising': -2.5, 'victimization': -2.3, 'victimizations': -1.5, 'victimize': -2.5, 'victimized': -1.8, 'victimizer': -1.8, 'victimizers': -1.6, 'victimizes': -1.5, 'victimizing': -2.6, 'victimless': 0.6, 'victimologies': -0.6, 'victimologist': -0.5, 'victimologists': -0.4, 'victimology': 0.3, 'victims': -1.3, 'vigilant': 0.7, 'vigor': 1.1, 'vigorish': -0.4, 'vigorishes': 0.4, 'vigoroso': 1.5, 'vigorously': 0.5, 'vigorousness': 0.4, 'vigors': 1.0, 'vigour': 0.9, 'vigours': 0.4, 'vile': -3.1, 'villain': -2.6, 'villainess': -2.9, 'villainesses': -2.0, 'villainies': -2.3, 'villainous': -2.0, 'villainously': -2.9, 'villainousness': -2.7, 'villains': -3.4, 'villainy': -2.6, 'vindicate': 0.3, 'vindicated': 1.8, 'vindicates': 1.6, 'vindicating': -1.1, 'violate': -2.2, 'violated': -2.4, 'violater': -2.6, 'violaters': -2.4, 'violates': -2.3, 'violating': -2.5, 'violation': -2.2, 'violations': -2.4, 'violative': -2.4, 'violator': -2.4, 'violators': -1.9, 'violence': -3.1, 'violent': -2.9, 'violently': -2.8, 'virtue': 1.8, 'virtueless': -1.4, 'virtues': 1.5, 'virtuosa': 1.7, 'virtuosas': 1.8, 'virtuose': 1.0, 'virtuosi': 0.9, 'virtuosic': 2.2, 'virtuosity': 2.1, 'virtuoso': 2.0, 'virtuosos': 1.8, 'virtuous': 2.4, 'virtuously': 1.8, 'virtuousness': 2.0, 'virulent': -2.7, 'vision': 1.0, 'visionary': 2.4, 'visioning': 1.1, 'visions': 0.9, 'vital': 1.2, 'vitalise': 1.1, 'vitalised': 0.6, 'vitalises': 1.1, 'vitalising': 2.1, 'vitalism': 0.2, 'vitalist': 0.3, 'vitalists': 0.3, 'vitalities': 1.2, 'vitality': 1.3, 'vitalization': 1.6, 'vitalizations': 0.8, 'vitalize': 1.6, 'vitalized': 1.5, 'vitalizes': 1.4, 'vitalizing': 1.3, 'vitally': 1.1, 'vitals': 1.1, 'vitamin': 1.2, 'vitriolic': -2.1, 'vivacious': 1.8, 'vociferous': -0.8, 'vulnerabilities': -0.6, 'vulnerability': -0.9, 'vulnerable': -0.9, 'vulnerableness': -1.1, 'vulnerably': -1.2, 'vulture': -2.0, 'vultures': -1.3, 'w00t': 2.2, 'walkout': -1.3, 'walkouts': -0.7, 'wanker': -2.5, 'want': 0.3, 'war': -2.9, 'warfare': -1.2, 'warfares': -1.8, 'warm': 0.9, 'warmblooded': 0.2, 'warmed': 1.1, 'warmer': 1.2, 'warmers': 1.0, 'warmest': 1.7, 'warmhearted': 1.8, 'warmheartedness': 2.7, 'warming': 0.6, 'warmish': 1.4, 'warmly': 1.7, 'warmness': 1.5, 'warmonger': -2.9, 'warmongering': -2.5, 'warmongers': -2.8, 'warmouth': 0.4, 'warmouths': -0.8, 'warms': 1.1, 'warmth': 2.0, 'warmup': 0.4, 'warmups': 0.8, 'warn': -0.4, 'warned': -1.1, 'warning': -1.4, 'warnings': -1.2, 'warns': -0.4, 'warred': -2.4, 'warring': -1.9, 'wars': -2.6, 'warsaw': -0.1, 'warsaws': -0.2, 'warship': -0.7, 'warships': -0.5, 'warstle': 0.1, 'waste': -1.8, 'wasted': -2.2, 'wasting': -1.7, 'wavering': -0.6, 'weak': -1.9, 'weaken': -1.8, 'weakened': -1.3, 'weakener': -1.6, 'weakeners': -1.3, 'weakening': -1.3, 'weakens': -1.3, 'weaker': -1.9, 'weakest': -2.3, 'weakfish': -0.2, 'weakfishes': -0.6, 'weakhearted': -1.6, 'weakish': -1.2, 'weaklier': -1.5, 'weakliest': -2.1, 'weakling': -1.3, 'weaklings': -1.4, 'weakly': -1.8, 'weakness': -1.8, 'weaknesses': -1.5, 'weakside': -1.1, 'wealth': 2.2, 'wealthier': 2.2, 'wealthiest': 2.2, 'wealthily': 2.0, 'wealthiness': 2.4, 'wealthy': 1.5, 'weapon': -1.2, 'weaponed': -1.4, 'weaponless': 0.1, 'weaponry': -0.9, 'weapons': -1.9, 'weary': -1.1, 'weep': -2.7, 'weeper': -1.9, 'weepers': -1.1, 'weepie': -0.4, 'weepier': -1.8, 'weepies': -1.6, 'weepiest': -2.4, 'weeping': -1.9, 'weepings': -1.9, 'weeps': -1.4, 'weepy': -1.3, 'weird': -0.7, 'weirder': -0.5, 'weirdest': -0.9, 'weirdie': -1.3, 'weirdies': -1.0, 'weirdly': -1.2, 'weirdness': -0.9, 'weirdnesses': -0.7, 'weirdo': -1.8, 'weirdoes': -1.3, 'weirdos': -1.1, 'weirds': -0.6, 'weirdy': -0.9, 'welcome': 2.0, 'welcomed': 1.4, 'welcomely': 1.9, 'welcomeness': 2.0, 'welcomer': 1.4, 'welcomers': 1.9, 'welcomes': 1.7, 'welcoming': 1.9, 'well': 1.1, 'welladay': 0.3, 'wellaway': -0.8, 'wellborn': 1.8, 'welldoer': 2.5, 'welldoers': 1.6, 'welled': 0.4, 'wellhead': 0.1, 'wellheads': 0.5, 'wellhole': -0.1, 'wellies': 0.4, 'welling': 1.6, 'wellness': 1.9, 'wells': 1.0, 'wellsite': 0.5, 'wellspring': 1.5, 'wellsprings': 1.4, 'welly': 0.2, 'wept': -2.0, 'whimsical': 0.3, 'whine': -1.5, 'whined': -0.9, 'whiner': -1.2, 'whiners': -0.6, 'whines': -1.8, 'whiney': -1.3, 'whining': -0.9, 'whitewash': 0.1, 'whore': -3.3, 'whored': -2.8, 'whoredom': -2.1, 'whoredoms': -2.4, 'whorehouse': -1.1, 'whorehouses': -1.9, 'whoremaster': -1.9, 'whoremasters': -1.5, 'whoremonger': -2.6, 'whoremongers': -2.0, 'whores': -3.0, 'whoreson': -2.2, 'whoresons': -2.5, 'wicked': -2.4, 'wickeder': -2.2, 'wickedest': -2.9, 'wickedly': -2.1, 'wickedness': -2.1, 'wickednesses': -2.2, 'widowed': -2.1, 'willingness': 1.1, 'wimp': -1.4, 'wimpier': -1.0, 'wimpiest': -0.9, 'wimpiness': -1.2, 'wimpish': -1.6, 'wimpishness': -0.2, 'wimple': -0.2, 'wimples': -0.3, 'wimps': -1.0, 'wimpy': -0.9, 'win': 2.8, 'winnable': 1.8, 'winned': 1.8, 'winner': 2.8, 'winners': 2.1, 'winning': 2.4, 'winningly': 2.3, 'winnings': 2.5, 'winnow': -0.3, 'winnower': -0.1, 'winnowers': -0.2, 'winnowing': -0.1, 'winnows': -0.2, 'wins': 2.7, 'wisdom': 2.4, 'wise': 2.1, 'wiseacre': -1.2, 'wiseacres': -0.1, 'wiseass': -1.8, 'wiseasses': -1.5, 'wisecrack': -0.1, 'wisecracked': -0.5, 'wisecracker': -0.1, 'wisecrackers': 0.1, 'wisecracking': -0.6, 'wisecracks': -0.3, 'wised': 1.5, 'wiseguys': 0.3, 'wiselier': 0.9, 'wiseliest': 1.6, 'wisely': 1.8, 'wiseness': 1.9, 'wisenheimer': -1.0, 'wisenheimers': -1.4, 'wisents': 0.4, 'wiser': 1.2, 'wises': 1.3, 'wisest': 2.1, 'wisewomen': 1.3, 'wish': 1.7, 'wishes': 0.6, 'wishing': 0.9, 'witch': -1.5, 'withdrawal': 0.1, 'woe': -1.8, 'woebegone': -2.6, 'woebegoneness': -1.1, 'woeful': -1.9, 'woefully': -1.7, 'woefulness': -2.1, 'woes': -1.9, 'woesome': -1.2, 'won': 2.7, 'wonderful': 2.7, 'wonderfully': 2.9, 'wonderfulness': 2.9, 'woo': 2.1, 'woohoo': 2.3, 'woot': 1.8, 'worn': -1.2, 'worried': -1.2, 'worriedly': -2.0, 'worrier': -1.8, 'worriers': -1.7, 'worries': -1.8, 'worriment': -1.5, 'worriments': -1.9, 'worrisome': -1.7, 'worrisomely': -2.0, 'worrisomeness': -1.9, 'worrit': -2.1, 'worrits': -1.2, 'worry': -1.9, 'worrying': -1.4, 'worrywart': -1.8, 'worrywarts': -1.5, 'worse': -2.1, 'worsen': -2.3, 'worsened': -1.9, 'worsening': -2.0, 'worsens': -2.1, 'worser': -2.0, 'worship': 1.2, 'worshiped': 2.4, 'worshiper': 1.0, 'worshipers': 0.9, 'worshipful': 0.7, 'worshipfully': 1.1, 'worshipfulness': 1.6, 'worshiping': 1.0, 'worshipless': -0.6, 'worshipped': 2.7, 'worshipper': 0.6, 'worshippers': 0.8, 'worshipping': 1.6, 'worships': 1.4, 'worst': -3.1, 'worth': 0.9, 'worthless': -1.9, 'worthwhile': 1.4, 'worthy': 1.9, 'wow': 2.8, 'wowed': 2.6, 'wowing': 2.5, 'wows': 2.0, 'wowser': -1.1, 'wowsers': 1.0, 'wrathful': -2.7, 'wreck': -1.9, 'wrong': -2.1, 'wronged': -1.9, 'yay': 2.4, 'yeah': 1.2, 'yearning': 0.5, 'yeees': 1.7, 'yep': 1.2, 'yes': 1.7, 'youthful': 1.3, 'yucky': -1.8, 'yummy': 2.4, 'zealot': -1.9, 'zealots': -0.8, 'zealous': 0.5, '{:': 1.8, '|-0': -1.2, '|-:': -0.8, '|-:>': -1.6, '|-o': -1.2, '|:': -0.5, '|;-)': 2.2, '|=': -0.4, '|^:': -1.1, '|o:': -0.9, '||-:': -2.3, '}:': -2.1, '}:(': -2.0, '}:)': 0.4, '}:-(': -2.1, '}:-)': 0.3}\n"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "sa = SentimentIntensityAnalyzer()\n",
    "print(sa.lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(\"( '}{' )\", 1.6), (\"can't stand\", -2.0), ('fed up', -1.8), ('screwed up', -1.5)]\n"
     ]
    }
   ],
   "source": [
    "score = [(tok, score) for tok, score in sa.lexicon.items() if \" \" in tok]\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "7504\n"
     ]
    }
   ],
   "source": [
    "print(len(sa.lexicon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'neg': 0.0, 'neu': 0.661, 'pos': 0.339, 'compound': 0.6249}\n"
     ]
    }
   ],
   "source": [
    "print(sa.polarity_scores(text=\"Python is very readble and it's great for NLP\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'neg': 0.0, 'neu': 0.711, 'pos': 0.289, 'compound': 0.431}\n"
     ]
    }
   ],
   "source": [
    "print(sa.polarity_scores(text=\"Python is not a bad for most application.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'neg': 0.608, 'neu': 0.392, 'pos': 0.0, 'compound': -0.4767}\n"
     ]
    }
   ],
   "source": [
    "print(sa.polarity_scores(text=\"Python is terrible.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"Absolutely perfect! Love it! :) XD\", \"Horrible! Completely useless :(\", \"It was OK, Some good and some bad things\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+0.9558: Absolutely perfect! Love it! :) XD\n",
      "-0.8768: Horrible! Completely useless :(\n",
      "-0.1531: It was OK, Some good and some bad things\n"
     ]
    }
   ],
   "source": [
    "for doc in corpus:\n",
    "    scores = sa.polarity_scores(doc)\n",
    "    print(\"{:+}: {}\".format(scores['compound'], doc))"
   ]
  },
  {
   "source": [
    "## Ranking\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from collections import Counter\n",
    "import copy\n",
    "import math\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "docs = [\"The faster Harry got to the store, the faster and faster Harry would get home.\"]\n",
    "docs.append(\"Harry is hairy and faster than Jill.\")\n",
    "docs.append(\"Jill is not as hairy as Harry.\")\n",
    "\n",
    "doc_tokens = []\n",
    "for doc in docs:\n",
    "    doc_tokens += [sorted(tokenizer.tokenize(doc.lower()))]\n",
    "\n",
    "all_doc_tokens = sum(doc_tokens, [])\n",
    "lexicon = sorted(all_doc_tokens)\n",
    "\n",
    "def cosine_sim(vec1, vec2):\n",
    "    vec1 = [val for val in vec1.values()]\n",
    "    vec2 = [val for val in vec2.values()]\n",
    "\n",
    "\n",
    "    dot_prod = 0\n",
    "    for i, v in enumerate(vec1):\n",
    "        dot_prod += v * vec2[i]\n",
    "\n",
    "    mag_1 = math.sqrt(sum([x**2 for x in vec1]))\n",
    "    mag_2 = math.sqrt(sum([x**2 for x in vec2]))\n",
    "\n",
    "    return dot_prod / (mag_1 * mag_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "zero_vector = OrderedDict((token, 0) for token in lexicon)\n",
    "document_tfidf_vectors = []\n",
    "for doc in docs:    \n",
    "    vec = copy.copy(zero_vector)    \n",
    "    tokens = tokenizer.tokenize(doc.lower())    \n",
    "    token_counts = Counter(tokens)    \n",
    "    \n",
    "    for key, value in token_counts.items():        \n",
    "        docs_containing_key = 0        \n",
    "        for _doc in docs:            \n",
    "            if key in _doc:                \n",
    "                docs_containing_key += 1        \n",
    "            tf = value / len(lexicon)        \n",
    "            if docs_containing_key:            \n",
    "                idf = len(docs) / docs_containing_key        \n",
    "            else:            \n",
    "                idf = 0        \n",
    "            vec[key] = tf * idf    \n",
    "        document_tfidf_vectors.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "OrderedDict([(',', 0.09090909090909091), ('.', 0.030303030303030304), ('and', 0.045454545454545456), ('as', 0), ('faster', 0.13636363636363635), ('get', 0.09090909090909091), ('got', 0.09090909090909091), ('hairy', 0), ('harry', 0.0), ('home', 0.09090909090909091), ('is', 0), ('jill', 0), ('not', 0), ('store', 0.09090909090909091), ('than', 0), ('the', 0.2727272727272727), ('to', 0.09090909090909091), ('would', 0.09090909090909091)])\n"
     ]
    }
   ],
   "source": [
    "query = \"How long does it take to get to the store?\"\n",
    "query_vec = copy.copy(zero_vector)\n",
    "\n",
    "tokens = tokenizer.tokenize(query.lower())\n",
    "token_counts = Counter(tokens)\n",
    "\n",
    "for key, value in token_counts.items():\n",
    "    doc_contains_key = 0\n",
    "    for _doc in docs:\n",
    "        if key in _doc:\n",
    "            docs_containing_key += 1\n",
    "        tf = value / len(lexicon)\n",
    "        if doc_contains_key:\n",
    "            idf = len(docs) / doc_contains_key\n",
    "        else:\n",
    "            idf = 0\n",
    "        query_vec[key] = tf * idf\n",
    "    document_tfidf_vectors.append(query_vec)\n",
    "\n",
    "print(document_tfidf_vectors[0])"
   ]
  },
  {
   "source": [
    "* Assim, temos uma representação vetorial k-dimensional (K é o número de palavras do vocabulário) de cada documento no corpus.\n",
    "\n",
    "* Podemos dizer que dois vetores, em um determinado espaço vetorial, são similares se tiverem um ângula semelhante.\n",
    "\n",
    "* Considerando cada vetor começando na origem (0, ...,0), os que alcançarem o mesmo ângulo são similares, mes que não alcancem a mesma distância (comprimento do vetor no espaço Euclideano).\n",
    "\n",
    "* Dois vetores são considerados similares se a similaridade do cosseno for alta; portanto, você pode encontrar a similaridade entre dois vetores se estes minimizarem a função:\n",
    "\n",
    "    * $\\cos \\Theta = \\frac{A . B}{|A| . |B|}$\n",
    "\n",
    "* Para calcular a similaridade entre dois documentos, podemos tratar a consulta em si como um documento e, portanto, obter a representação vetorial baseada em TF-IDF.\n",
    "\n",
    "* A última etapa é encontrar os documentos cujos vetores têm os maiores valores de similaridades da distância de cosseno com a consulta e retorna-los como resultado da pesquisa."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'How long does it take to get to the store ?'\n",
    "query_vec  = copy.copy(zero_vector)\n",
    "\n",
    "tokens = tokenizer.tokenize(query.lower())\n",
    "token_counts = Counter(tokens)\n",
    "\n",
    "for key, valule in token_counts.items():\n",
    "    doc_contains_key = 0\n",
    "    for _doc in docs:\n",
    "        if key in _doc.lower():\n",
    "            doc_contains_key += 1\n",
    "        if doc_contains_key == 0:\n",
    "            continue\n",
    "        tf = value / len(tokens)\n",
    "        idf = len(docs) / doc_contains_key\n",
    "        query_vec[key] = tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({'how': 1,\n",
       "         'long': 1,\n",
       "         'does': 1,\n",
       "         'it': 1,\n",
       "         'take': 1,\n",
       "         'to': 2,\n",
       "         'get': 1,\n",
       "         'the': 1,\n",
       "         'store': 1,\n",
       "         '?': 1})"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "token_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.6954006683576303\n0.6954006683576303\n0.6954006683576303\n"
     ]
    }
   ],
   "source": [
    "print(cosine_sim(query_vec, document_tfidf_vectors[0]))\n",
    "print(cosine_sim(query_vec, document_tfidf_vectors[1]))\n",
    "print(cosine_sim(query_vec, document_tfidf_vectors[2]))"
   ]
  },
  {
   "source": [
    "* O doc 0 possui a maior relevância para a consulta. E assim, é possível encontrar documentos relevantes em qualquer corpus, sejam artigos na Wikipedia ou tweets.\n",
    "\n",
    "* Observe que o mecanismo de busca do Google funciona de forma diferente, baseado em índices dos vetores TF-IDF (não é o nosso objetivo aqui).\n",
    "\n",
    "* A maioria dos mecanismos de pesquisa pode responder em tempo constante (0 (1)) porque eles usam um índice invertido.\n",
    "\n",
    "* Para saber mais sobre índices:\n",
    "\n",
    "    * https://pypi.org/project/Whoosh/\n",
    "\n",
    "    * https://github.com/Mplsbeb/whoosh\n",
    "\n",
    "* Esa aplicação de busca por similaridade é uma etapa importante de um pipeline para NLP.\n",
    "\n",
    "* Alguns chatbots dependem exclusivamente de um mecanismo de busca como seu único algoritmo para gerar respostas.\n",
    "\n",
    "* Você precisa executar uma etapa adicional para transformar seu indice de pesquisa simples (TF-IDF) em um chatbot.\n",
    "\n",
    "* Uma possibilidade para o chatbot, é necessario armazenar dados de treinamento em pares de perguntas e respostas apropriadas.\n",
    "\n",
    "* Em seguida, calculamos o TF-IDF para pesquisar uma pergunta mais semelhante com o texto de entrada do usuário.\n",
    "\n",
    "* Em vez de retornar a instrução mais similares de um banco de dados, retornamos a resposta associada a esta intrução."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}